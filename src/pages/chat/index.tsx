import { useState, useRef, useEffect } from 'react'
import { View, Text, ScrollView, Textarea } from '@tarojs/components'
import Taro from '@tarojs/taro'
import { AtIcon } from 'taro-ui'
import CustomIcon from '../../components/CustomIcon'
import VoiceWaveform from '../../components/VoiceWaveform'
import { useChatStore } from '../../stores/chat'
import { useUserStore } from '../../stores/user'
import { formatRelativeTime } from '../../utils/date'

import {
  mockStartRecording,
  mockStopRecording,
  shouldUseMockAudio,
} from '../../services/mockAudio'
import { chatApi } from '../../services/api'
import './index.scss'

interface ChatMessage {
  id: string
  type: 'user' | 'ai'
  content: string
  audioUrl?: string
  duration?: number // è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
  timestamp: number
  translation?: string
  helpContent?: {
    original: string
    corrected: string
  }
  reaction?: string // emojiåé¦ˆ
}

interface SpeechToTextResponse {
  text: string
  confidence: number
  language: string
}

interface ChatResponse {
  content: string
  audioUrl?: string
  duration?: number
}

const ChatPage = () => {
  const { messages, isRecording, addMessage, startRecording, stopRecording } =
    useChatStore()
  const { updateDailyUsage } = useUserStore()

  // æœ¬åœ°çŠ¶æ€
  const [isTyping, setIsTyping] = useState(false)
  const [showTextInput, setShowTextInput] = useState(false)
  const [textInput, setTextInput] = useState('')
  const [playingAudioId, setPlayingAudioId] = useState<string | null>(null)
  const [messageReactions, setMessageReactions] = useState<Map<string, string>>(
    new Map()
  )
  const [aiStatus, setAiStatus] = useState<'online' | 'offline' | 'typing'>(
    'online'
  )

  // å¼•ç”¨
  const scrollViewRef = useRef<{
    scrollToBottom?: (options?: { animated?: boolean }) => void
  } | null>(null)
  const recordingTimer = useRef<NodeJS.Timeout | null>(null)

  // é¡µé¢åˆå§‹åŒ–
  useEffect(() => {
    // æ·»åŠ æ¬¢è¿æ¶ˆæ¯
    if (messages.length === 0) {
      const welcomeMessage: ChatMessage = {
        id: Date.now().toString(),
        type: 'ai',
        content:
          "Hi! I'm your AI English tutor. Let's practice speaking English together! ğŸ¦†",
        timestamp: Date.now(),
        translation: 'å—¨ï¼æˆ‘æ˜¯ä½ çš„AIè‹±è¯­è€å¸ˆã€‚è®©æˆ‘ä»¬ä¸€èµ·ç»ƒä¹ è¯´è‹±è¯­å§ï¼ğŸ¦†',
      }
      addMessage(welcomeMessage)
    }
  }, [messages.length, addMessage])

  // AIçŠ¶æ€ç®¡ç†
  useEffect(() => {
    if (isTyping) {
      setAiStatus('typing')
    } else {
      setAiStatus('online')
    }
  }, [isTyping])

  // æ»šåŠ¨åˆ°åº•éƒ¨
  const scrollToBottom = () => {
    setTimeout(() => {
      scrollViewRef.current?.scrollToBottom?.({ animated: true })
    }, 100)
  }

  // å¼€å§‹å½•éŸ³
  const handleStartRecording = async () => {
    try {
      // åœ¨å¼€å‘ç¯å¢ƒä¸‹ä½¿ç”¨mockå½•éŸ³
      if (shouldUseMockAudio()) {
        console.log('ğŸ¤ å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨Mockå½•éŸ³åŠŸèƒ½')
        startRecording()
        await mockStartRecording()

        // è®¾ç½®æœ€å¤§å½•éŸ³æ—¶é•¿
        recordingTimer.current = setTimeout(() => {
          handleStopRecording()
        }, 60000) // æœ€å¤šå½•éŸ³60ç§’
        return
      }

      // ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çœŸå®å½•éŸ³
      const { authSetting } = await Taro.getSetting()

      if (!authSetting['scope.record']) {
        try {
          await Taro.authorize({
            scope: 'scope.record',
          })
        } catch (_error) {
          Taro.showModal({
            title: 'éœ€è¦å½•éŸ³æƒé™',
            content: 'è¯·åœ¨è®¾ç½®ä¸­å¼€å¯å½•éŸ³æƒé™ä»¥ä½¿ç”¨è¯­éŸ³å¯¹è¯åŠŸèƒ½',
            showCancel: false,
          })
          return
        }
      }

      startRecording()

      // å¼€å§‹å½•éŸ³
      Taro.startRecord({
        success: res => {
          console.log('å½•éŸ³æˆåŠŸ', res)
        },
        fail: err => {
          console.error('å½•éŸ³å¤±è´¥', err)
          stopRecording()
          Taro.showToast({
            title: 'å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•',
            icon: 'error',
          })
        },
      })

      // è®¾ç½®æœ€å¤§å½•éŸ³æ—¶é•¿
      recordingTimer.current = setTimeout(() => {
        handleStopRecording()
      }, 60000) // æœ€å¤šå½•éŸ³60ç§’
    } catch (error) {
      console.error('å¼€å§‹å½•éŸ³é”™è¯¯', error)
      Taro.showToast({
        title: 'å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•',
        icon: 'error',
      })
    }
  }

  // åœæ­¢å½•éŸ³
  const handleStopRecording = async () => {
    if (!isRecording) return

    if (recordingTimer.current) {
      clearTimeout(recordingTimer.current)
      recordingTimer.current = null
    }

    stopRecording()

    try {
      // åœ¨å¼€å‘ç¯å¢ƒä¸‹ä½¿ç”¨mockå½•éŸ³
      if (shouldUseMockAudio()) {
        console.log('ğŸ¤ å¼€å‘ç¯å¢ƒï¼šåœæ­¢Mockå½•éŸ³')
        const mockAudioData = await mockStopRecording()

        try {
          // åˆ›å»ºæ¨¡æ‹Ÿçš„FormData
          const formData = new FormData()
          // åœ¨å°ç¨‹åºç¯å¢ƒä¸­ï¼Œä½¿ç”¨Fileå¯¹è±¡ä»£æ›¿Blob
          const mockFile = new File(['mock audio data'], 'mock-recording.wav', {
            type: 'audio/wav',
          })
          formData.append('audio', mockFile)

          // ä½¿ç”¨MSW APIè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
          const speechResult = await chatApi.speechToText(formData)

          // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
          const userMessage: ChatMessage = {
            id: Date.now().toString(),
            type: 'user',
            content: (speechResult.data as SpeechToTextResponse).text,
            audioUrl: mockAudioData.audioUrl,
            duration: mockAudioData.duration,
            timestamp: Date.now(),
          }

          addMessage(userMessage)
          scrollToBottom()

          // AIå›å¤
          handleAIResponse(userMessage.content)
        } catch (error) {
          console.error('Mockè¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
          Taro.showToast({
            title: 'è¯­éŸ³è¯†åˆ«å¤±è´¥',
            icon: 'error',
          })
        }
        return
      }

      // ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çœŸå®å½•éŸ³
      Taro.stopRecord({
        success: res => {
          const audioPath = (res as unknown as { tempFilePath: string })
            .tempFilePath

          // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³æ—¶é•¿ï¼‰
          const userMessage: ChatMessage = {
            id: Date.now().toString(),
            type: 'user',
            content: "Hello, I'd like to practice speaking English.", // æ¨¡æ‹Ÿè¯­éŸ³è½¬æ–‡å­—ç»“æœ
            audioUrl: audioPath,
            duration: Math.floor(Math.random() * 10 + 3), // æ¨¡æ‹Ÿ3-13ç§’çš„è¯­éŸ³
            timestamp: Date.now(),
          }

          addMessage(userMessage)
          scrollToBottom()

          // æ¨¡æ‹ŸAIå¤„ç†å’Œå›å¤
          handleAIResponse(userMessage.content)
        },
        fail: err => {
          console.error('åœæ­¢å½•éŸ³å¤±è´¥', err)
          Taro.showToast({
            title: 'å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•',
            icon: 'error',
          })
        },
      })
    } catch (error) {
      console.error('åœæ­¢å½•éŸ³é”™è¯¯', error)
    }
  }

  // AIå›å¤å¤„ç†
  const handleAIResponse = async (userInput: string) => {
    setIsTyping(true)

    try {
      // ä½¿ç”¨MSW APIå‘é€æ¶ˆæ¯å¹¶è·å–AIå›å¤
      const response = await chatApi.sendMessage({
        sessionId: 'default-session',
        content: userInput,
        type: 'voice',
      })

      const aiResponseData = response.data as ChatResponse

      const aiMessage: ChatMessage = {
        id: Date.now().toString(),
        type: 'ai',
        content: aiResponseData.content,
        audioUrl: aiResponseData.audioUrl,
        duration: aiResponseData.duration || Math.floor(Math.random() * 5 + 3),
        timestamp: Date.now(),
      }

      setIsTyping(false)
      addMessage(aiMessage)
      scrollToBottom()
    } catch (error) {
      console.error('AIå›å¤å¤±è´¥:', error)
      setIsTyping(false)
      Taro.showToast({
        title: 'AIå›å¤å¤±è´¥ï¼Œè¯·é‡è¯•',
        icon: 'error',
      })
    }
  }

  // å‘é€æ–‡æœ¬æ¶ˆæ¯
  const handleSendText = async () => {
    if (!textInput.trim()) return

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      type: 'user',
      content: textInput.trim(),
      timestamp: Date.now(),
    }

    addMessage(userMessage)
    setTextInput('')
    setShowTextInput(false)
    scrollToBottom()

    // AIå›å¤
    handleAIResponse(userMessage.content)
  }

  // æ’­æ”¾éŸ³é¢‘
  const handlePlayAudio = (messageId: string, audioUrl?: string) => {
    if (!audioUrl) return

    if (playingAudioId === messageId) {
      // åœæ­¢æ’­æ”¾
      Taro.stopBackgroundAudio()
      setPlayingAudioId(null)
    } else {
      // å¼€å§‹æ’­æ”¾
      Taro.playBackgroundAudio({
        dataUrl: audioUrl,
        success: () => {
          setPlayingAudioId(messageId)
        },
        fail: err => {
          console.error('æ’­æ”¾éŸ³é¢‘å¤±è´¥', err)
          Taro.showToast({
            title: 'æ’­æ”¾å¤±è´¥',
            icon: 'error',
          })
        },
      })

      // æ¨¡æ‹Ÿæ’­æ”¾ç»“æŸ
      setTimeout(() => {
        setPlayingAudioId(null)
      }, 5000)
    }
  }

  // ç¿»è¯‘åŠŸèƒ½
  const handleTranslate = (messageId: string, content: string) => {
    updateDailyUsage('translate')

    // æ¨¡æ‹Ÿç¿»è¯‘ç»“æœ
    const translations: { [key: string]: string } = {
      "Hi! I'm your AI English tutor. Let's practice speaking English together! ğŸ¦†":
        'å—¨ï¼æˆ‘æ˜¯ä½ çš„AIè‹±è¯­è€å¸ˆã€‚è®©æˆ‘ä»¬ä¸€èµ·ç»ƒä¹ è¯´è‹±è¯­å§ï¼ğŸ¦†',
      "That's great! What topics would you like to discuss today?":
        'å¤ªå¥½äº†ï¼ä»Šå¤©ä½ æƒ³è®¨è®ºä»€ä¹ˆè¯é¢˜å‘¢ï¼Ÿ',
      'Excellent pronunciation! Your English is improving.':
        'å‘éŸ³å¾ˆæ£’ï¼ä½ çš„è‹±è¯­åœ¨è¿›æ­¥ã€‚',
      'I understand. Could you tell me more about that?':
        'æˆ‘æ˜ç™½äº†ã€‚ä½ èƒ½è¯¦ç»†è¯´è¯´å—ï¼Ÿ',
      'Interesting point! How do you usually practice English?':
        'æœ‰è¶£çš„è§‚ç‚¹ï¼ä½ å¹³æ—¶æ˜¯æ€ä¹ˆç»ƒä¹ è‹±è¯­çš„ï¼Ÿ',
      'Good job! Let me help you with a more natural expression.':
        'åšå¾—å¥½ï¼è®©æˆ‘å¸®ä½ ç”¨æ›´åœ°é“çš„è¡¨è¾¾æ–¹å¼ã€‚',
    }

    const translation = translations[content] || 'è¿™æ˜¯ç¿»è¯‘ç»“æœç¤ºä¾‹'

    // æ›´æ–°æ¶ˆæ¯æ·»åŠ ç¿»è¯‘
    const updatedMessages = messages.map(msg =>
      msg.id === messageId ? { ...msg, translation } : msg
    )

    // è¿™é‡Œåº”è¯¥è°ƒç”¨storeæ–¹æ³•æ›´æ–°æ¶ˆæ¯
    console.log('ç¿»è¯‘:', translation, updatedMessages)

    Taro.showToast({
      title: 'ç¿»è¯‘å®Œæˆ',
      icon: 'success',
    })
  }

  // Emojiåé¦ˆ
  const handleEmojiReaction = (messageId: string, emoji: string) => {
    const newReactions = new Map(messageReactions)

    // å¦‚æœå·²ç»æ˜¯åŒä¸€ä¸ªemojiï¼Œåˆ™å–æ¶ˆåé¦ˆ
    if (newReactions.get(messageId) === emoji) {
      newReactions.delete(messageId)
    } else {
      newReactions.set(messageId, emoji)
    }

    setMessageReactions(newReactions)
  }

  // è¿”å›ä¸Šä¸€é¡µ
  const handleBack = () => {
    Taro.navigateBack()
  }

  return (
    <View className="chat-page">
      {/* AIå¤´éƒ¨ä¿¡æ¯ */}
      <View className="ai-header">
        <View className="header-content">
          <View className="back-btn" onClick={handleBack}>
            <AtIcon value="chevron-left" size="24" color="#fff" />
          </View>

          <View className="ai-info">
            <View className="ai-avatar">
              <Text className="avatar-emoji">ğŸ¤–</Text>
            </View>

            <View className="ai-details">
              <Text className="ai-name">Emma (AIå¤–æ•™)</Text>
              <View className="ai-status">
                <View className={`status-dot ${aiStatus}`}></View>
                <Text className="status-text">
                  {aiStatus === 'typing' ? 'æ­£åœ¨è¾“å…¥...' : 'åœ¨çº¿'}
                </Text>
              </View>
            </View>
          </View>

          <View className="header-actions">
            <CustomIcon name="more-horizontal" size={24} color="#fff" />
          </View>
        </View>
      </View>

      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <ScrollView
        className="message-container"
        scrollY
        scrollIntoView="bottom"
        ref={scrollViewRef}
        enhanced
        showScrollbar={false}
      >
        {messages.map(message => (
          <View key={message.id} className={`message ${message.type}`}>
            {/* å¤´åƒ */}
            <View className="message-avatar">
              {message.type === 'ai' ? (
                <View className="avatar-ai">
                  <Text className="avatar-emoji">ğŸ¤–</Text>
                </View>
              ) : (
                <View className="avatar-user">
                  <Text className="avatar-emoji">ğŸ˜Š</Text>
                </View>
              )}
            </View>

            {/* æ¶ˆæ¯å†…å®¹ */}
            <View className="message-content">
              <View className="message-bubble">
                {/* è¯­éŸ³æ¶ˆæ¯æ˜¾ç¤ºæ³¢å½¢ */}
                {message.audioUrl && message.duration ? (
                  <View
                    className="message-voice"
                    onClick={() =>
                      handlePlayAudio(message.id, message.audioUrl)
                    }
                  >
                    <View className="play-button">
                      <AtIcon
                        value={playingAudioId === message.id ? 'pause' : 'play'}
                        size="16"
                        color={message.type === 'user' ? '#fff' : '#7c3aed'}
                      />
                    </View>
                    <VoiceWaveform
                      duration={message.duration}
                      isPlaying={playingAudioId === message.id}
                    />
                  </View>
                ) : (
                  <Text className="message-text">{message.content}</Text>
                )}

                {/* ç¿»è¯‘å†…å®¹ */}
                {message.translation && (
                  <View className="translation">
                    <Text className="translation-text">
                      {message.translation}
                    </Text>
                  </View>
                )}
              </View>

              {/* æ¶ˆæ¯æ“ä½œå’Œæ—¶é—´ */}
              <View className="message-footer">
                <Text className="message-time">
                  {formatRelativeTime(message.timestamp)}
                </Text>

                {message.type === 'ai' && (
                  <View className="message-actions">
                    <View
                      className="action-btn"
                      onClick={() =>
                        handleTranslate(message.id, message.content)
                      }
                    >
                      <CustomIcon name="globe" size={14} />
                      <Text className="action-text">ç¿»è¯‘</Text>
                    </View>
                  </View>
                )}
              </View>
            </View>

            {/* Emojiåé¦ˆ */}
            {message.type === 'user' && (
              <View className="emoji-reaction">
                <View
                  className={`emoji-btn ${messageReactions.get(message.id) === 'ğŸ˜Š' ? 'active' : ''}`}
                  onClick={() => handleEmojiReaction(message.id, 'ğŸ˜Š')}
                >
                  ğŸ˜Š
                </View>
              </View>
            )}
          </View>
        ))}

        {isTyping && (
          <View className="message ai typing-message">
            <View className="message-avatar">
              <View className="avatar-ai">
                <Text className="avatar-emoji">ğŸ¤–</Text>
              </View>
            </View>
            <View className="message-content">
              <View className="typing-indicator">
                <View className="typing-dot"></View>
                <View className="typing-dot"></View>
                <View className="typing-dot"></View>
              </View>
            </View>
          </View>
        )}

        <View id="bottom" style={{ height: '1rpx' }}></View>
      </ScrollView>

      {/* è¾“å…¥å·¥å…·æ  */}
      <View className="input-bar">
        <View className="input-left">
          <View className="icon-btn" onClick={() => {}}>
            <CustomIcon name="plus-circle" size={24} color="#999" />
          </View>
        </View>

        <View
          className={`record-button ${isRecording ? 'recording' : ''}`}
          onTouchStart={handleStartRecording}
          onTouchEnd={handleStopRecording}
        >
          <CustomIcon name="mic" size={20} color="#fff" />
          <Text className="record-text">
            {isRecording ? 'æ¾å¼€ç»“æŸ' : 'æŒ‰ä½è¯´è¯'}
          </Text>
          {shouldUseMockAudio() && (
            <Text className="mock-indicator">ğŸ¤ Mock</Text>
          )}
        </View>

        <View className="input-right">
          <View className="icon-btn emoji-btn" onClick={() => {}}>
            <Text className="emoji-icon">ğŸ˜Š</Text>
          </View>
        </View>
      </View>

      {/* æ–‡æœ¬è¾“å…¥å¼¹çª— */}
      {showTextInput && (
        <View className="text-input-modal">
          <View className="input-panel">
            <View className="input-header">
              <Text className="input-title">è¾“å…¥æ–‡å­—</Text>
              <View
                className="close-btn"
                onClick={() => setShowTextInput(false)}
              >
                <CustomIcon name="x-circle" size={20} />
              </View>
            </View>

            <Textarea
              className="text-input"
              value={textInput}
              onInput={(e: { detail: { value: string } }) =>
                setTextInput(e.detail.value)
              }
              placeholder="è¾“å…¥ä½ æƒ³è¯´çš„è¯..."
              maxlength={500}
              autoFocus
            />

            <View className="input-actions">
              <View className="send-btn" onClick={handleSendText}>
                å‘é€
              </View>
            </View>
          </View>
        </View>
      )}
    </View>
  )
}

export default ChatPage
